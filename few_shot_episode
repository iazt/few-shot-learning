def train_few_shot(net, n_epochs, support_loader, query_loader, optimizer, criterion):
  total_support = len(support_loader)*support_loader.batch_size
  total_query = len(query_loader)*query_loader.batch_size
  
  softmax = nn.Softmax(dim=1)
  net.train()
  for epoch in range(n_epochs):   
    running_loss, running_acc = 0.0, 0.0
    for i, data in enumerate(support_loader, 0): # Obtener batch
      labels = data[0].cuda()
      inputs = data[1].float().cuda()
      optimizer.zero_grad()
      outputs = net(inputs)
      loss = criterion(softmax(outputs), labels)
      loss.backward()
      optimizer.step()
      

  net.eval()
  running_acc = 0.0
  valid_loss = 0.0
  
  for i, data in enumerate(query_loader, 0):
    labels = data[0].cuda()
    inputs = data[1].float().cuda()
    with torch.no_grad():
      Y_pred = net(inputs)
    max_prob, max_idx = torch.max(Y_pred.data, dim=1)
    running_acc += torch.sum(max_idx == labels).item()
    loss = criterion(Y_pred, labels)
    # record validation loss
    valid_loss+= loss.item()

  return running_acc/total_query, valid_loss/total_query